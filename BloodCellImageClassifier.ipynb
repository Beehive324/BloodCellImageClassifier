{
 "cells": [
  {
   "cell_type": "raw",
   "id": "c08bdf1f-e313-4f57-a7ae-d2189ee619a3",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#!pip install cv2\n",
    "#!pip install ImageDataGenerator\n",
    "#!pip install plotly\n",
    "!pip install seaborn\n",
    "\n",
    "\n",
    "#imports to be used in the program\n",
    "import matplotlib.pyplot\n",
    "import numpy as np # imports numpy\n",
    "import os # imports operating system\n",
    "import random # imports random\n",
    "#from PIL import image #import PIL\n",
    "import sklearn\n",
    "import cv2\n",
    "import scipy\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skimage.io import imread\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "import cv2 #\n",
    "\n",
    "#notebook stability\n",
    "np.random.seed(42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ed23f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads train images from the folder\n",
    "\n",
    "import os # imports the operating system\n",
    "\n",
    "root = \"train\" # assigns root to train\n",
    "\n",
    "frames = os.listdir(root)\n",
    "\n",
    "\n",
    "len(frames) # check how many images there are\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913f7129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test to see how the images look\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "root = \"test\"\n",
    "frames = os.listdir(root)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=5)\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Loop over the first 10 frames\n",
    "for i in range(10):\n",
    "    print(frames[i])  # prints the number of frames\n",
    "    filepath = os.path.join(root, frames[i])\n",
    "    img = Image.open(filepath)\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(cv2.imread(filepath), cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply the median filter for smoothing\n",
    "    med_filt = cv2.medianBlur(gray, 5)\n",
    "    \n",
    "    # Apply the Gaussian filter\n",
    "    guss_filt = cv2.GaussianBlur(gray, (9, 9), 0)\n",
    "    \n",
    "    # Apply histogram normalization\n",
    "    histo = cv2.equalizeHist(gray)\n",
    "    \n",
    "    # Apply edge detection filters\n",
    "    edge = cv2.Canny(gray, 100, 200)\n",
    "    \n",
    "    axs[i].imshow(edge, cmap='gray')\n",
    "    axs[i].set_title(frames[i])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32835d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Turn and apply filters to test images into a numpy array\n",
    "from matplotlib.image import imread\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "root = \"test\"\n",
    "frames = os.listdir(root)\n",
    "\n",
    "# Create an empty list to store the image arrays`\n",
    "images = []\n",
    "\n",
    "# Loop over the image files and apply filters\n",
    "for frame in frames:\n",
    "    # Read in the image file\n",
    "    image = imread(os.path.join(root, frame))\n",
    "    #Turn images into gray, apply gray filter\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # apply the median filter for smoothing\n",
    "    med_filt = cv2.medianBlur(gray, 5)\n",
    "    #apply gaussian filter\n",
    "    guss_filt = cv2.GaussianBlur(gray,(9,9), 0)\n",
    "    #Apply histo norm filter\n",
    "    histo = cv2.equalizeHist(gray)\n",
    "    \n",
    "    #apply edge detection filters\n",
    "    edge = cv2.Canny(gray,100,200)\n",
    "    \n",
    "    #validation_split\n",
    "    validation_split = 0.8\n",
    "\n",
    "   \n",
    "    # Append the image array to the list\n",
    "    images.append(image)\n",
    "\n",
    "# Convert the list of image arrays to a numpy array\n",
    "images_array = np.array(images)\n",
    "\n",
    "print(images_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa5a1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train images + apply filters\n",
    "from matplotlib.image import imread\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "root = \"train\"\n",
    "frames = os.listdir(root)\n",
    "\n",
    "# Create an empty list to store the image arrays\n",
    "images = []\n",
    "\n",
    "# Loop over the image files and apply filters\n",
    "for frame in frames:\n",
    "    # Read in the image file\n",
    "    image = imread(os.path.join(root, frame))\n",
    "    # Turn images into gray, apply gray filter\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply the median filter for smoothing\n",
    "    med_filt = cv2.medianBlur(gray, 5)\n",
    "    # Apply Gaussian filter\n",
    "    guss_filt = cv2.GaussianBlur(gray,(9,9), 0)\n",
    "    # Apply histogram normalization\n",
    "    histo = cv2.equalizeHist(gray)\n",
    "    # Apply edge detection filters\n",
    "    edge = cv2.Canny(gray,100,200)\n",
    "    \n",
    "    # Append the filtered image arrays to the list\n",
    "    images.append(gray)\n",
    "    images.append(med_filt)\n",
    "    images.append(guss_filt)\n",
    "    images.append(histo)\n",
    "    images.append(edge)\n",
    "\n",
    "# Convert the list of image arrays to a numpy array\n",
    "images_array = np.array(images)\n",
    "\n",
    "print(images_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5e2a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigns each train image to each label from 0 to 7 and creates a folfer for each for keras image generator\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "\n",
    "# Reads the text file with the labels and splits them into each individual part\n",
    "with open('train.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Extract the file paths and labels from the lines in the train.txt file\n",
    "file_paths = []\n",
    "labels = []\n",
    "for line in lines:\n",
    "    line = line.strip().split()\n",
    "    file_paths.append(line[0])\n",
    "    labels.append(int(line[1]))\n",
    "\n",
    "X = images_array\n",
    "y = np.array(labels)\n",
    "\n",
    "# Create folders for each label\n",
    "for label in range(8):\n",
    "    folder_name = f'label_{label}'\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "# Move images to their corresponding folders based on labels\n",
    "for idx in range(len(file_paths)):\n",
    "    label = y[idx]\n",
    "    source_path = file_paths[idx]\n",
    "    destination_folder = f'label_{label}'\n",
    "    destination_path = os.path.join(destination_folder, os.path.basename(source_path))\n",
    "    shutil.move(source_path, destination_path)\n",
    "\n",
    "# Print the labels and corresponding images for labels 0 to 7\n",
    "for label in range(8):\n",
    "    label_folder = f'label_{label}'\n",
    "    label_indices = np.where(y == label)[0]\n",
    "    print(f\"Label {label}:\")\n",
    "    for idx in label_indices:\n",
    "        if label == y[idx]:\n",
    "            image = X[idx]\n",
    "            plt.imshow(image)\n",
    "            plt.title(f\"Image {file_paths[idx]}\")\n",
    "            plt.show()\n",
    "\n",
    "print(y)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149a2234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reads the text file with the labels and splits them into each individual part\n",
    "with open('train.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Extract the file paths and labels from the lines in the train.txt file\n",
    "file_paths = []\n",
    "labels = []\n",
    "for line in lines:\n",
    "    line = line.strip().split()\n",
    "    file_paths.append(line[0])\n",
    "    labels.append(int(line[1]))\n",
    "\n",
    "# Load the corresponding images into an array\n",
    "X = []\n",
    "for file_path in file_paths:\n",
    "    image = plt.imread(file_path)\n",
    "    X.append(image)\n",
    "X = np.array(X)\n",
    "y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd9aad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the labels and corresponding images for labels 0 to 7\n",
    "for label in range(8):  # Iterate over labels 0 to 7\n",
    "    label_indices = np.where(y == label)[0]\n",
    "    print(f\"Label {label}:\")\n",
    "    for idx in label_indices:\n",
    "        if label == y[idx]:  # Check if the label of the current image matches the current label\n",
    "            image = X[idx]\n",
    "            plt.imshow(image)\n",
    "            plt.title(f\"Image {file_paths[idx]}\")\n",
    "            plt.show()\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676e98ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flow for image for image datagenerator\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "\n",
    "root = \"train\" # assigns root to train\n",
    "\n",
    "train_images1 = os.listdir(root)\n",
    "\n",
    "root2 = \"test\" # assigns root2 to test\n",
    "\n",
    "test_images2 = os.listdir(root2)\n",
    "\n",
    "\n",
    "len(train_images1) # check how many images there are\n",
    "\n",
    "train_images = 'C:/Users/fairs/COM2028_CW_2023/COM2028_2023/train'\n",
    "test_images = 'C:/Users/fairs/COM2028_CW_2023/COM2028_2023/test'\n",
    " \n",
    "\n",
    "#train data generator + image processing technique\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # rescale pixel values to [0, 1]\n",
    "    shear_range=0.2,  # apply shear transformation with angle range of 0.2 radians\n",
    "    zoom_range=0.2,  # apply zoom transformation with a zoom range of 0.2\n",
    "    horizontal_flip=True,  # flip images horizontally\n",
    "    rotation_range=20,  # apply rotation with angle range of 20 degrees\n",
    "    width_shift_range=0.2,  # apply width shift with width range of 0.2\n",
    "    height_shift_range=0.2,  # apply height shift with height range of 0.2\n",
    "    fill_mode='nearest',  # fill missing pixels with the nearest value\n",
    "    channel_shift_range=0.2,  # apply channel shift with a range of 0.2\n",
    "    validation_split=0.2  # specify the validation split as 20%\n",
    ")                         \n",
    "\n",
    "#test data generator\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(train_images,\n",
    "                                                 target_size=(64,64),\n",
    "                                                 #batch_size = 32,\n",
    "                                                 color_mode='rgb',\n",
    "                                                 shuffle=True,\n",
    "                                                 subset ='training',\n",
    "                                                 seed = None,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 classes=(['label_0', 'label_1', 'label_2', 'label_3', \n",
    "                                                             'label_4', 'label_5', 'label_6', 'label_7']\n",
    "                                                ))\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(test_images,\n",
    "                                            target_size = (64,64),\n",
    "                                            color_mode='rgb',\n",
    "                                            shuffle=False,\n",
    "                                            seed = None,\n",
    "                                            class_mode = 'categorical',\n",
    "                                           )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "validation_set = train_datagen.flow_from_directory(train_images,\n",
    "                                            target_size = (64,64),\n",
    "                                            color_mode='rgb',\n",
    "                                            shuffle=True,\n",
    "                                            seed = None,\n",
    "                                            subset='validation',       \n",
    "                                            class_mode = 'categorical',\n",
    "                                             classes=(['label_0', 'label_1', 'label_2', 'label_3', \n",
    "                                                             'label_4', 'label_5', 'label_6', 'label_7']\n",
    "                                                    ))\n",
    "                                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56ea426",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building our Model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.utils import plot_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2,os,math\n",
    "import numpy as np\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "np.random.seed(42) # consistency for this model\n",
    "\n",
    "num_classes_training_set = 8\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=(64,64,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes_training_set, activation='softmax'))\n",
    "\n",
    "opt = Adam(learning_rate=0.001)\n",
    "\n",
    "\n",
    "model.summary()\n",
    "plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bca5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and train the model\n",
    "model.compile(optimizer= opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01cb932",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "251/251 [==============================] - 36s 145ms/step - loss: 0.2451 - accuracy: 0.9145 - val_loss: 0.2413 - val_accuracy: 0.9193\n",
      "Epoch 78/100\n",
      "251/251 [==============================] - 36s 144ms/step - loss: 0.2552 - accuracy: 0.9133 - val_loss: 0.2506 - val_accuracy: 0.9153\n",
      "Epoch 79/100\n",
      "251/251 [==============================] - 36s 144ms/step - loss: 0.2515 - accuracy: 0.9132 - val_loss: 0.2281 - val_accuracy: 0.9233\n",
      "Epoch 80/100\n",
      "251/251 [==============================] - 36s 145ms/step - loss: 0.2402 - accuracy: 0.9128 - val_loss: 0.2050 - val_accuracy: 0.9294\n",
      "Epoch 81/100\n",
      "251/251 [==============================] - 36s 145ms/step - loss: 0.2503 - accuracy: 0.9129 - val_loss: 0.2030 - val_accuracy: 0.9344\n",
      "Epoch 82/100\n",
      "251/251 [==============================] - 36s 145ms/step - loss: 0.2403 - accuracy: 0.9142 - val_loss: 0.2901 - val_accuracy: 0.8953\n",
      "Epoch 83/100\n",
      "251/251 [==============================] - 36s 145ms/step - loss: 0.2405 - accuracy: 0.9168 - val_loss: 0.2251 - val_accuracy: 0.9259\n",
      "Epoch 84/100\n",
      "251/251 [==============================] - 36s 145ms/step - loss: 0.2622 - accuracy: 0.9102 - val_loss: 0.2716 - val_accuracy: 0.9053\n",
      "Epoch 85/100\n",
      "251/251 [==============================] - 36s 145ms/step - loss: 0.2476 - accuracy: 0.9105 - val_loss: 0.2322 - val_accuracy: 0.9168\n",
      "Epoch 86/100\n",
      "251/251 [==============================] - 36s 144ms/step - loss: 0.2455 - accuracy: 0.9119 - val_loss: 0.2131 - val_accuracy: 0.9183\n",
      "Epoch 87/100\n",
      "251/251 [==============================] - 36s 145ms/step - loss: 0.2405 - accuracy: 0.9142 - val_loss: 0.2034 - val_accuracy: 0.9294\n",
      "Epoch 88/100\n",
      "251/251 [==============================] - 36s 145ms/step - loss: 0.2394 - accuracy: 0.9174 - val_loss: 0.2304 - val_accuracy: 0.9193\n",
      "Epoch 89/100\n",
      "251/251 [==============================] - 36s 144ms/step - loss: 0.2429 - accuracy: 0.9152 - val_loss: 0.2465 - val_accuracy: 0.9133\n",
      "Epoch 90/100\n",
      "251/251 [==============================] - 36s 145ms/step - loss: 0.2328 - accuracy: 0.9170 - val_loss: 0.2309 - val_accuracy: 0.9254\n",
      "Epoch 91/100\n",
      "251/251 [==============================] - 36s 144ms/step - loss: 0.2345 - accuracy: 0.9157 - val_loss: 0.2469 - val_accuracy: 0.9133\n",
      "Epoch 92/100\n",
      "251/251 [==============================] - 37s 146ms/step - loss: 0.2397 - accuracy: 0.9153 - val_loss: 0.3438 - val_accuracy: 0.8863\n",
      "Epoch 93/100\n",
      "251/251 [==============================] - 36s 145ms/step - loss: 0.2314 - accuracy: 0.9195 - val_loss: 0.2184 - val_accuracy: 0.9173\n",
      "Epoch 94/100\n",
      "251/251 [==============================] - 36s 144ms/step - loss: 0.2273 - accuracy: 0.9203 - val_loss: 0.2135 - val_accuracy: 0.9228\n",
      "Epoch 95/100\n",
      "251/251 [==============================] - 36s 144ms/step - loss: 0.2434 - accuracy: 0.9113 - val_loss: 0.2191 - val_accuracy: 0.9264\n",
      "Epoch 96/100\n",
      "251/251 [==============================] - 36s 145ms/step - loss: 0.2348 - accuracy: 0.9182 - val_loss: 0.1967 - val_accuracy: 0.9364\n",
      "Epoch 97/100\n",
      "251/251 [==============================] - 36s 145ms/step - loss: 0.2246 - accuracy: 0.9195 - val_loss: 0.2248 - val_accuracy: 0.9238\n",
      "Epoch 98/100\n",
      "251/251 [==============================] - 36s 145ms/step - loss: 0.2539 - accuracy: 0.9114 - val_loss: 0.2669 - val_accuracy: 0.9043\n",
      "Epoch 99/100\n",
      "251/251 [==============================] - 36s 144ms/step - loss: 0.2397 - accuracy: 0.9184 - val_loss: 0.2747 - val_accuracy: 0.8973\n",
      "Epoch 100/100\n",
      "251/251 [==============================] - 36s 145ms/step - loss: 0.2381 - accuracy: 0.9167 - val_loss: 0.2292 - val_accuracy: 0.9223\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_set, epochs=100,batch_size =32, validation_data=validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df74f9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Accuracy:\", history.history['accuracy'][-1])\n",
    "print(\"Validation Accuracy:\", history.history['val_accuracy'][-1])\n",
    "print(\"Loss:\", history.history['loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7044b5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and Validation Accuracy Over Time, to determine overfitting and underfitting\n",
    "import plotly.express as px\n",
    "\n",
    "fig =px.line(\n",
    "history.history,\n",
    "    y=['accuracy', 'val_accuracy'],\n",
    "    labels={'index': \"Epoch\", 'value': \"Acc\"},\n",
    "    title=\"Training and Validation Accuracy Over Time\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5289b853",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig =px.line(\n",
    "history.history,\n",
    "    y=['loss', 'val_loss'],\n",
    "    labels={'index': \"Epoch\", 'value': \"Loss\"},\n",
    "    title=\"Training and Validation Loss Over Time\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f971c225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot accuracy for the model\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model_accuracy')\n",
    "plt.xlabel('accuracy')\n",
    "plt.ylabel('epoch')\n",
    "\n",
    "plt.legend(['train','test'],loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac2890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('fs00602(model2).h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4dae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you have a variable 'predictions' containing the data to be written into the text file\n",
    "# Replace this with your actual data\n",
    "\n",
    "# Create a list of filenames\n",
    "filenames = ['test/{:06d}.jpg'.format(i - 1) for i in range(1, len(predictions_int) + 1)]\n",
    "\n",
    "# Create a DataFrame with filenames and corresponding predictions\n",
    "df = pd.DataFrame({'Filename': filenames, 'Prediction': predictions_int})\n",
    "\n",
    "# Write the DataFrame into a text file called 'test.txt' with the desired format\n",
    "df.to_csv('test2.txt', index=False, sep=' ', header=False, index_label=None)\n",
    "\n",
    "print(\"Data has been written to test.txt successfully.\")\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e2493d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
